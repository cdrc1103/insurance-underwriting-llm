{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition and Exploration\n",
    "\n",
    "This notebook downloads and explores the Multi-Turn Insurance Underwriting dataset from Hugging Face.\n",
    "\n",
    "**Dataset**: `snorkelai/Multi-Turn-Insurance-Underwriting`\n",
    "\n",
    "**Objectives**:\n",
    "1. Download dataset from Hugging Face\n",
    "2. Understand data schema and structure\n",
    "3. Analyze distribution of examples\n",
    "4. Identify data quality issues\n",
    "5. Document findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from Hugging Face\n",
    "print(\"Loading dataset from Hugging Face...\")\n",
    "dataset = load_dataset(\"snorkelai/Multi-Turn-Insurance-Underwriting\")\n",
    "\n",
    "print(f\"\\nDataset structure: {dataset}\")\n",
    "print(f\"\\nNumber of examples: {len(dataset['train'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine first example\n",
    "example = dataset['train'][0]\n",
    "print(\"First example keys:\")\n",
    "print(json.dumps({k: type(v).__name__ for k, v in example.items()}, indent=2))\n",
    "\n",
    "print(\"\\nFirst example:\")\n",
    "print(json.dumps(example, indent=2, default=str)[:2000] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Schema Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze schema\n",
    "print(\"Dataset features:\")\n",
    "print(dataset['train'].features)\n",
    "\n",
    "# Check column names\n",
    "print(\"\\nColumn names:\")\n",
    "print(dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas for easier analysis\n",
    "df = dataset['train'].to_pandas()\n",
    "print(f\"Total examples: {len(df)}\")\n",
    "print(f\"\\nDataFrame shape: {df.shape}\")\n",
    "print(f\"\\nDataFrame columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing value percentages:\")\n",
    "print((df.isnull().sum() / len(df) * 100).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conversation Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze conversation structure\n",
    "# Note: The actual structure depends on the dataset format\n",
    "# This is a placeholder that will be updated based on actual data\n",
    "\n",
    "def count_conversation_turns(example):\n",
    "    \"\"\"Count number of turns in a conversation.\"\"\"\n",
    "    # Placeholder - will be updated based on actual data structure\n",
    "    if 'messages' in example:\n",
    "        return len(example['messages'])\n",
    "    elif 'conversation' in example:\n",
    "        return len(example['conversation'])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply to dataset\n",
    "conversation_lengths = [count_conversation_turns(ex) for ex in dataset['train']]\n",
    "\n",
    "print(f\"Conversation length statistics:\")\n",
    "print(f\"  Mean: {np.mean(conversation_lengths):.2f}\")\n",
    "print(f\"  Median: {np.median(conversation_lengths):.2f}\")\n",
    "print(f\"  Min: {np.min(conversation_lengths)}\")\n",
    "print(f\"  Max: {np.max(conversation_lengths)}\")\n",
    "print(f\"  Std: {np.std(conversation_lengths):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize conversation length distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(conversation_lengths, bins=20, edgecolor='black')\n",
    "plt.xlabel('Number of Turns')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Conversation Lengths')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Company Profile Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze company profiles\n",
    "# Placeholder - will be updated based on actual data structure\n",
    "\n",
    "def extract_company_info(example):\n",
    "    \"\"\"Extract company information from example.\"\"\"\n",
    "    # Placeholder - will be updated based on actual structure\n",
    "    return {\n",
    "        'revenue': example.get('annual_revenue'),\n",
    "        'employees': example.get('number_of_employees'),\n",
    "        'industry': example.get('industry'),\n",
    "        'state': example.get('state'),\n",
    "    }\n",
    "\n",
    "# Extract company information\n",
    "company_info = [extract_company_info(ex) for ex in dataset['train']]\n",
    "company_df = pd.DataFrame(company_info)\n",
    "\n",
    "print(\"Company profile fields:\")\n",
    "print(company_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Task Type Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze task types\n",
    "# Placeholder - will be updated based on actual data\n",
    "\n",
    "def identify_task_type(example):\n",
    "    \"\"\"Identify the task type of an example.\"\"\"\n",
    "    # Placeholder - will be updated based on actual structure\n",
    "    # Common task types: appetite check, product recommendation, eligibility, etc.\n",
    "    return example.get('task_type', 'unknown')\n",
    "\n",
    "task_types = [identify_task_type(ex) for ex in dataset['train']]\n",
    "task_distribution = Counter(task_types)\n",
    "\n",
    "print(\"Task type distribution:\")\n",
    "for task, count in task_distribution.most_common():\n",
    "    print(f\"  {task}: {count} ({count/len(task_types)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize task distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "tasks, counts = zip(*task_distribution.most_common())\n",
    "plt.bar(tasks, counts)\n",
    "plt.xlabel('Task Type')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Task Types')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Text Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze text lengths (approximate token counts)\n",
    "def estimate_tokens(text):\n",
    "    \"\"\"Estimate token count (rough approximation: words / 0.75).\"\"\"\n",
    "    return int(len(text.split()) / 0.75)\n",
    "\n",
    "def get_total_text_length(example):\n",
    "    \"\"\"Get total text length for an example.\"\"\"\n",
    "    # Placeholder - will be updated based on actual structure\n",
    "    total = 0\n",
    "    if 'messages' in example:\n",
    "        for msg in example['messages']:\n",
    "            if isinstance(msg, dict) and 'content' in msg:\n",
    "                total += estimate_tokens(msg['content'])\n",
    "    return total\n",
    "\n",
    "text_lengths = [get_total_text_length(ex) for ex in dataset['train']]\n",
    "\n",
    "print(f\"Text length statistics (tokens):\")\n",
    "print(f\"  Mean: {np.mean(text_lengths):.0f}\")\n",
    "print(f\"  Median: {np.median(text_lengths):.0f}\")\n",
    "print(f\"  Min: {np.min(text_lengths)}\")\n",
    "print(f\"  Max: {np.max(text_lengths)}\")\n",
    "print(f\"  Std: {np.std(text_lengths):.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Quality Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify data quality issues\n",
    "issues = []\n",
    "\n",
    "for idx, example in enumerate(dataset['train']):\n",
    "    # Check for tool calls (to be excluded)\n",
    "    example_str = str(example).lower()\n",
    "    if 'tool_call' in example_str or 'function_call' in example_str:\n",
    "        issues.append({\n",
    "            'index': idx,\n",
    "            'issue': 'Contains tool/function calls',\n",
    "        })\n",
    "    \n",
    "    # Check for missing company profile\n",
    "    if not any(field in example for field in ['company', 'business', 'annual_revenue']):\n",
    "        issues.append({\n",
    "            'index': idx,\n",
    "            'issue': 'Missing company profile',\n",
    "        })\n",
    "    \n",
    "    # Check for empty conversations\n",
    "    if count_conversation_turns(example) == 0:\n",
    "        issues.append({\n",
    "            'index': idx,\n",
    "            'issue': 'Empty conversation',\n",
    "        })\n",
    "\n",
    "print(f\"Total data quality issues found: {len(issues)}\")\n",
    "if issues:\n",
    "    issues_df = pd.DataFrame(issues)\n",
    "    print(\"\\nIssue distribution:\")\n",
    "    print(issues_df['issue'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Sample Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a few sample examples\n",
    "print(\"Sample Example 1:\")\n",
    "print(\"=\" * 80)\n",
    "print(json.dumps(dataset['train'][0], indent=2, default=str)[:1500])\n",
    "print(\"\\n...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample Example 2:\")\n",
    "print(\"=\" * 80)\n",
    "print(json.dumps(dataset['train'][1], indent=2, default=str)[:1500])\n",
    "print(\"\\n...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Findings\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Dataset Size**: [TO BE FILLED AFTER RUNNING]\n",
    "2. **Schema**: [TO BE FILLED AFTER RUNNING]\n",
    "3. **Conversation Structure**: [TO BE FILLED AFTER RUNNING]\n",
    "4. **Task Distribution**: [TO BE FILLED AFTER RUNNING]\n",
    "5. **Data Quality**: [TO BE FILLED AFTER RUNNING]\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Implement preprocessing pipeline based on schema\n",
    "2. Handle data quality issues (filter tool calls, etc.)\n",
    "3. Create train/validation/test splits\n",
    "4. Implement tokenization for chosen model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset locally for faster access\n",
    "output_dir = project_root / \"data\" / \"raw\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset.save_to_disk(str(output_dir / \"insurance_underwriting\"))\n",
    "print(f\"Dataset saved to: {output_dir / 'insurance_underwriting'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save exploration summary\n",
    "summary = {\n",
    "    'total_examples': len(dataset['train']),\n",
    "    'conversation_length_stats': {\n",
    "        'mean': float(np.mean(conversation_lengths)),\n",
    "        'median': float(np.median(conversation_lengths)),\n",
    "        'min': int(np.min(conversation_lengths)),\n",
    "        'max': int(np.max(conversation_lengths)),\n",
    "    },\n",
    "    'text_length_stats': {\n",
    "        'mean': float(np.mean(text_lengths)),\n",
    "        'median': float(np.median(text_lengths)),\n",
    "        'min': int(np.min(text_lengths)),\n",
    "        'max': int(np.max(text_lengths)),\n",
    "    },\n",
    "    'task_distribution': dict(task_distribution),\n",
    "    'quality_issues': len(issues),\n",
    "}\n",
    "\n",
    "summary_path = project_root / \"data\" / \"exploration_summary.json\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"Summary saved to: {summary_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
