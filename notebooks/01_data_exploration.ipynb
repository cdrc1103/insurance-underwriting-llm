{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition and Exploration\n",
    "\n",
    "This notebook downloads and explores the Multi-Turn Insurance Underwriting dataset from Hugging Face.\n",
    "\n",
    "**Dataset**: `snorkelai/Multi-Turn-Insurance-Underwriting`\n",
    "\n",
    "**Objectives**:\n",
    "1. Download dataset from Hugging Face\n",
    "2. Understand data schema and structure\n",
    "3. Analyze distribution of examples\n",
    "4. Identify data quality issues\n",
    "5. Document findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from Hugging Face...\n",
      "\n",
      "Dataset structure: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['primary id', 'company task id', 'assistant model name', 'task', 'trace', 'reference answer', 'correct', 'company name', 'annual revenue', 'number of employees', 'total payroll', 'number of vehicles', 'building construction', 'state', 'company description', 'lob'],\n",
      "        num_rows: 380\n",
      "    })\n",
      "})\n",
      "\n",
      "Number of examples: 380\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from Hugging Face\n",
    "print(\"Loading dataset from Hugging Face...\")\n",
    "dataset = load_dataset(\"snorkelai/Multi-Turn-Insurance-Underwriting\")\n",
    "\n",
    "print(f\"\\nDataset structure: {dataset}\")\n",
    "print(f\"\\nNumber of examples: {len(dataset['train'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'primary id': 0,\n",
       " 'company task id': 1097,\n",
       " 'assistant model name': 'o3',\n",
       " 'task': 'Product Recommendations',\n",
       " 'trace': [{'additional_kwargs': '{}',\n",
       "   'content': 'Would you mind finding out which other insurance products might be suitable for this company?',\n",
       "   'id': '9510799c-cccc-43ac-ac39-9ed402d22f35',\n",
       "   'response_metadata': '{}',\n",
       "   'role': 'user',\n",
       "   'tool_calls': '',\n",
       "   'type': 'underwriter',\n",
       "   'usage_metadata': ''},\n",
       "  {'additional_kwargs': '{}',\n",
       "   'content': 'Sure, I can help with that.  \\n\\n1. What industry or type of business is the company in (e.g., retail clothing store, metal-parts manufacturer, restaurant, etc.)?  \\n2. Which insurance products (lines of business) do they already purchase from us, if any?',\n",
       "   'id': '6f73a76f-e008-44bb-9bd2-29f9b8817983',\n",
       "   'response_metadata': '{}',\n",
       "   'role': 'assistant',\n",
       "   'tool_calls': '',\n",
       "   'type': 'user-facing assistant',\n",
       "   'usage_metadata': ''},\n",
       "  {'additional_kwargs': '{}',\n",
       "   'content': 'Two-year college, associate degrees and certificates.',\n",
       "   'id': 'd9eb5f4b-4f31-4e51-b148-3825409d7877',\n",
       "   'response_metadata': '{}',\n",
       "   'role': 'user',\n",
       "   'tool_calls': '',\n",
       "   'type': 'underwriter',\n",
       "   'usage_metadata': ''},\n",
       "  {'additional_kwargs': '{}',\n",
       "   'content': 'Thank you. Which lines of business does the college already have with us (e.g., Property, General Liability, Workers’ Compensation, Commercial Auto, Cyber, Professional Liability, etc.)?',\n",
       "   'id': 'ecded222-0219-40bc-a14e-1fd3a1396dce',\n",
       "   'response_metadata': '{}',\n",
       "   'role': 'assistant',\n",
       "   'tool_calls': '',\n",
       "   'type': 'user-facing assistant',\n",
       "   'usage_metadata': ''},\n",
       "  {'additional_kwargs': '{}',\n",
       "   'content': 'I do not know.',\n",
       "   'id': '98dd6a5a-10a2-47cf-a65d-5c1f04f31175',\n",
       "   'response_metadata': '{}',\n",
       "   'role': 'user',\n",
       "   'tool_calls': '',\n",
       "   'type': 'underwriter',\n",
       "   'usage_metadata': ''},\n",
       "  {'additional_kwargs': \"{'tool_calls': [{'id': 'call_pNrs7NKIyKbXv3JT6T9DAHVb', 'function': {'arguments': '{}', 'name': 'get_underwriting_guidelines'}, 'type': 'function'}], 'refusal': None}\",\n",
       "   'content': '',\n",
       "   'id': 'run--257a5438-1a75-4257-8b42-12eeeb162b87-0',\n",
       "   'response_metadata': \"{'token_usage': {'completion_tokens': 278, 'prompt_tokens': 1234, 'total_tokens': 1512, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1024}}, 'model_name': 'o3-2025-04-16', 'system_fingerprint': None, 'id': 'chatcmpl-BfWMua7hEoQ0aQJ6w9IlSseCtxC5w', 'finish_reason': 'tool_calls', 'logprobs': None}\",\n",
       "   'role': 'assistant',\n",
       "   'tool_calls': \"[{'name': 'get_underwriting_guidelines', 'args': {}, 'id': 'call_pNrs7NKIyKbXv3JT6T9DAHVb', 'type': 'tool_call'}]\",\n",
       "   'type': 'internal assistant',\n",
       "   'usage_metadata': \"{'input_tokens': 1234, 'output_tokens': 278, 'total_tokens': 1512, 'input_token_details': {'audio': 0, 'cache_read': 1024}, 'output_token_details': {'audio': 0, 'reasoning': 256}}\"},\n",
       "  {'additional_kwargs': '{}',\n",
       "   'content': '***General***\\nWe write policies for small businesses only. Any business that fails to qualify as a \"small business\" is out of appetite, so we will not write a policy for it.\\n\\n***Property LOB***\\n\\nFor property LOB, business classes pertaining to hospitality or leasing are only in appetite if the building construction is sufficiently fire resistive. \\nThis means the building construction codes are either Type I or Type II.\\n\\nSpecifically, this is relevant to the following NAICS codes using the 2022 schema:\\n\\n531110\\tLessors of Residential Buildings and Dwellings\\n531120\\tLessors of Nonresidential Buildings\\n531130\\tLessors of Miniwarehouses and Self-Storage Units\\n531190\\tLessors of Other Real Estate Property\\n\\n721110\\tHotels (except Casino Hotels) and Motels\\n721120\\tCasino Hotels\\n721191\\tBed-and-Breakfast Inns\\n\\n***Policy Limits***\\n\\nFor most small business policies we recommend a per-occurence limit of $1 million and an aggregate limit of $2 million.\\n\\nHowever, for cyber liability insurance coverage: Industry, business type, amount, and type of customer data handled determine how much cyber insurance businesses need. \\nSpecifically we recommend much higher limits of $3 million per-occurence and $5 million aggregate for cyber LOB for the following NAICS classes:\\n\\nNAICS code 517: Telecommunications\\nNAICS code 518: Computing Infrastructure Providers, Data Processing, Web Hosting, and Related Services\\nNAICS code 52: Finance and Insurance\\nNAICS code 621: Ambulatory Health Care Services\\nNAICS code 622310: Specialty Hospitals\\nNAICS code 623: Nursing and Residential Care Facilities\\nNAICS code 92: Public Administration\\n\\n***Policy Deductibles***\\n\\nFor most small business policies we recommend a deductible of $500 across LOBs. \\n\\nHowever, for auto insurance we generally recommend a $1000 deductible, and for the following NAICS codes we recommend a $5000 deductible:\\n\\nNAICS code 484: Freight Trucking\\nNAICS code 4853: Taxi and Limousine Services\\nNAICS code 4854: School and Employee Bus Transportation\\nNAICS code 4855: Charter Bus Services\\nNAICS code 4871: Scenic and Sightseeing Transportation (Land)\\n\\n***Auto LOB***\\n\\nIf our appetite guide for an auto policy indicates \"qualified\", then we determine final appetite according to whether the applicant has over 20 vehicles, in which case we decline because the exposure is too high.\\n\\n***Worker\\'s Compensation LOB***\\n\\nIf our appetite guide for a worker\\'s compensation policy indicates \"qualified\", then we determine final appetite according to whether the applicant has a total annual payroll of over $5M, in which case we decline because the exposure is too high.\\n',\n",
       "   'id': '5cad8429-b36a-43f1-a796-c8d7a5f7cc61',\n",
       "   'response_metadata': '{}',\n",
       "   'role': 'assistant',\n",
       "   'tool_calls': '',\n",
       "   'type': 'tool',\n",
       "   'usage_metadata': ''},\n",
       "  {'additional_kwargs': '{}',\n",
       "   'content': 'FINAL ANSWER:   \\n\\nSuitable additional insurance products (lines of business) for a small, two-year college that grants associate degrees and certificates typically include:\\n\\n• General Liability – protects against third-party bodily injury or property-damage claims arising out of campus operations.  \\n• Property – covers buildings, contents, equipment, and business-income/extra-expense exposures such as a fire on campus.  \\n• Educators Professional Liability (Errors & Omissions) – protects against claims alleging improper academic advice, grading disputes, failure to educate, or discrimination.  \\n• Workers’ Compensation – required in most states for faculty, staff, and student workers; covers on-the-job injuries.  \\n• Cyber Liability – colleges collect and store sizable student PII and payment data; coverage would address data-breach costs, extortion, and network-interruption losses.  \\n• Commercial Auto – if the college owns vans, maintenance trucks, or shuttle buses; covers liability and physical damage.  \\n• Employment Practices Liability – addresses wrongful-termination, discrimination, or harassment allegations brought by employees or job applicants.  \\n• Umbrella/Excess – provides higher limits above underlying GL, Auto, and Employers Liability, helpful for premises-liability or athletic-injury suits.  \\n\\nRationale: Two-year colleges face premises-liability exposures from students and visitors, own instructional equipment and buildings that must be insured for property perils, employ faculty and staff who need workers’ compensation, handle sensitive student data (necessitating cyber), and have unique professional exposures related to educational services. An umbrella gives extra limits once primary policies exhaust. All of these fit standard small-business products All National writes and, absent any disqualifying size or construction factors, are generally in appetite.',\n",
       "   'id': '8db71c27-dfe0-4aa0-9011-797c776f4b8c',\n",
       "   'response_metadata': '{}',\n",
       "   'role': 'assistant',\n",
       "   'tool_calls': '',\n",
       "   'type': 'user-facing assistant',\n",
       "   'usage_metadata': ''}],\n",
       " 'reference answer': 'No other LOBs are in appetite for this company.',\n",
       " 'correct': False,\n",
       " 'company name': 'Central Gateway Community College',\n",
       " 'annual revenue': 64000000,\n",
       " 'number of employees': 580,\n",
       " 'total payroll': 32000000,\n",
       " 'number of vehicles': 25,\n",
       " 'building construction': 'Non-combustible – Examples included steel columns, beams and deck/floors.',\n",
       " 'state': 'Texas',\n",
       " 'company description': 'Central Gateway Community College is a prominent two-year institution in Dallas, Texas, providing associate degrees and technical certificates in a wide range of fields, including health sciences, business studies, and information technology. The college has multiple campuses, modern classrooms, laboratories, vocational workshops, and student housing. It also offers workforce development and continuing education programs through extensive online and in-person classes. Central Gateway owns a shuttle fleet and several maintenance vehicles, and insures its large campus properties and advanced technical equipment.',\n",
       " 'lob': 'general liability'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Schema Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset features:\n",
      "{'primary id': Value('int64'), 'company task id': Value('int64'), 'assistant model name': Value('string'), 'task': Value('string'), 'trace': List({'additional_kwargs': Value('string'), 'content': Value('string'), 'id': Value('string'), 'response_metadata': Value('string'), 'role': Value('string'), 'tool_calls': Value('string'), 'type': Value('string'), 'usage_metadata': Value('string')}), 'reference answer': Value('string'), 'correct': Value('bool'), 'company name': Value('string'), 'annual revenue': Value('int64'), 'number of employees': Value('int64'), 'total payroll': Value('int64'), 'number of vehicles': Value('int64'), 'building construction': Value('string'), 'state': Value('string'), 'company description': Value('string'), 'lob': Value('string')}\n",
      "\n",
      "Column names:\n",
      "['primary id', 'company task id', 'assistant model name', 'task', 'trace', 'reference answer', 'correct', 'company name', 'annual revenue', 'number of employees', 'total payroll', 'number of vehicles', 'building construction', 'state', 'company description', 'lob']\n"
     ]
    }
   ],
   "source": [
    "# Analyze schema\n",
    "print(\"Dataset features:\")\n",
    "print(dataset[\"train\"].features)\n",
    "\n",
    "# Check column names\n",
    "print(\"\\nColumn names:\")\n",
    "print(dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas for easier analysis\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "print(f\"Total examples: {len(df)}\")\n",
    "print(f\"\\nDataFrame shape: {df.shape}\")\n",
    "print(f\"\\nDataFrame columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing value percentages:\")\n",
    "print((df.isnull().sum() / len(df) * 100).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conversation Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze conversation structure\n",
    "# Note: The actual structure depends on the dataset format\n",
    "# This is a placeholder that will be updated based on actual data\n",
    "\n",
    "\n",
    "def count_conversation_turns(example):\n",
    "    \"\"\"Count number of turns in a conversation.\"\"\"\n",
    "    # Placeholder - will be updated based on actual data structure\n",
    "    if \"messages\" in example:\n",
    "        return len(example[\"messages\"])\n",
    "    elif \"conversation\" in example:\n",
    "        return len(example[\"conversation\"])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Apply to dataset\n",
    "conversation_lengths = [count_conversation_turns(ex) for ex in dataset[\"train\"]]\n",
    "\n",
    "print(\"Conversation length statistics:\")\n",
    "print(f\"  Mean: {np.mean(conversation_lengths):.2f}\")\n",
    "print(f\"  Median: {np.median(conversation_lengths):.2f}\")\n",
    "print(f\"  Min: {np.min(conversation_lengths)}\")\n",
    "print(f\"  Max: {np.max(conversation_lengths)}\")\n",
    "print(f\"  Std: {np.std(conversation_lengths):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize conversation length distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(conversation_lengths, bins=20, edgecolor=\"black\")\n",
    "plt.xlabel(\"Number of Turns\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Conversation Lengths\")\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Company Profile Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze company profiles\n",
    "# Placeholder - will be updated based on actual data structure\n",
    "\n",
    "\n",
    "def extract_company_info(example):\n",
    "    \"\"\"Extract company information from example.\"\"\"\n",
    "    # Placeholder - will be updated based on actual structure\n",
    "    return {\n",
    "        \"revenue\": example.get(\"annual_revenue\"),\n",
    "        \"employees\": example.get(\"number_of_employees\"),\n",
    "        \"industry\": example.get(\"industry\"),\n",
    "        \"state\": example.get(\"state\"),\n",
    "    }\n",
    "\n",
    "\n",
    "# Extract company information\n",
    "company_info = [extract_company_info(ex) for ex in dataset[\"train\"]]\n",
    "company_df = pd.DataFrame(company_info)\n",
    "\n",
    "print(\"Company profile fields:\")\n",
    "print(company_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Task Type Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze task types\n",
    "# Placeholder - will be updated based on actual data\n",
    "\n",
    "\n",
    "def identify_task_type(example):\n",
    "    \"\"\"Identify the task type of an example.\"\"\"\n",
    "    # Placeholder - will be updated based on actual structure\n",
    "    # Common task types: appetite check, product recommendation, eligibility, etc.\n",
    "    return example.get(\"task_type\", \"unknown\")\n",
    "\n",
    "\n",
    "task_types = [identify_task_type(ex) for ex in dataset[\"train\"]]\n",
    "task_distribution = Counter(task_types)\n",
    "\n",
    "print(\"Task type distribution:\")\n",
    "for task, count in task_distribution.most_common():\n",
    "    print(f\"  {task}: {count} ({count / len(task_types) * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize task distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "tasks, counts = zip(*task_distribution.most_common())\n",
    "plt.bar(tasks, counts)\n",
    "plt.xlabel(\"Task Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Task Types\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Text Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze text lengths (approximate token counts)\n",
    "def estimate_tokens(text):\n",
    "    \"\"\"Estimate token count (rough approximation: words / 0.75).\"\"\"\n",
    "    return int(len(text.split()) / 0.75)\n",
    "\n",
    "\n",
    "def get_total_text_length(example):\n",
    "    \"\"\"Get total text length for an example.\"\"\"\n",
    "    # Placeholder - will be updated based on actual structure\n",
    "    total = 0\n",
    "    if \"messages\" in example:\n",
    "        for msg in example[\"messages\"]:\n",
    "            if isinstance(msg, dict) and \"content\" in msg:\n",
    "                total += estimate_tokens(msg[\"content\"])\n",
    "    return total\n",
    "\n",
    "\n",
    "text_lengths = [get_total_text_length(ex) for ex in dataset[\"train\"]]\n",
    "\n",
    "print(\"Text length statistics (tokens):\")\n",
    "print(f\"  Mean: {np.mean(text_lengths):.0f}\")\n",
    "print(f\"  Median: {np.median(text_lengths):.0f}\")\n",
    "print(f\"  Min: {np.min(text_lengths)}\")\n",
    "print(f\"  Max: {np.max(text_lengths)}\")\n",
    "print(f\"  Std: {np.std(text_lengths):.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Quality Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify data quality issues\n",
    "issues = []\n",
    "\n",
    "for idx, example in enumerate(dataset[\"train\"]):\n",
    "    # Check for tool calls (to be excluded)\n",
    "    example_str = str(example).lower()\n",
    "    if \"tool_call\" in example_str or \"function_call\" in example_str:\n",
    "        issues.append(\n",
    "            {\n",
    "                \"index\": idx,\n",
    "                \"issue\": \"Contains tool/function calls\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Check for missing company profile\n",
    "    if not any(field in example for field in [\"company\", \"business\", \"annual_revenue\"]):\n",
    "        issues.append(\n",
    "            {\n",
    "                \"index\": idx,\n",
    "                \"issue\": \"Missing company profile\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Check for empty conversations\n",
    "    if count_conversation_turns(example) == 0:\n",
    "        issues.append(\n",
    "            {\n",
    "                \"index\": idx,\n",
    "                \"issue\": \"Empty conversation\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "print(f\"Total data quality issues found: {len(issues)}\")\n",
    "if issues:\n",
    "    issues_df = pd.DataFrame(issues)\n",
    "    print(\"\\nIssue distribution:\")\n",
    "    print(issues_df[\"issue\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Sample Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a few sample examples\n",
    "print(\"Sample Example 1:\")\n",
    "print(\"=\" * 80)\n",
    "print(json.dumps(dataset[\"train\"][0], indent=2, default=str)[:1500])\n",
    "print(\"\\n...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample Example 2:\")\n",
    "print(\"=\" * 80)\n",
    "print(json.dumps(dataset[\"train\"][1], indent=2, default=str)[:1500])\n",
    "print(\"\\n...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Findings\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Dataset Size**: [TO BE FILLED AFTER RUNNING]\n",
    "2. **Schema**: [TO BE FILLED AFTER RUNNING]\n",
    "3. **Conversation Structure**: [TO BE FILLED AFTER RUNNING]\n",
    "4. **Task Distribution**: [TO BE FILLED AFTER RUNNING]\n",
    "5. **Data Quality**: [TO BE FILLED AFTER RUNNING]\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Implement preprocessing pipeline based on schema\n",
    "2. Handle data quality issues (filter tool calls, etc.)\n",
    "3. Create train/validation/test splits\n",
    "4. Implement tokenization for chosen model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset locally for faster access\n",
    "output_dir = project_root / \"data\" / \"raw\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset.save_to_disk(str(output_dir / \"insurance_underwriting\"))\n",
    "print(f\"Dataset saved to: {output_dir / 'insurance_underwriting'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save exploration summary\n",
    "summary = {\n",
    "    \"total_examples\": len(dataset[\"train\"]),\n",
    "    \"conversation_length_stats\": {\n",
    "        \"mean\": float(np.mean(conversation_lengths)),\n",
    "        \"median\": float(np.median(conversation_lengths)),\n",
    "        \"min\": int(np.min(conversation_lengths)),\n",
    "        \"max\": int(np.max(conversation_lengths)),\n",
    "    },\n",
    "    \"text_length_stats\": {\n",
    "        \"mean\": float(np.mean(text_lengths)),\n",
    "        \"median\": float(np.median(text_lengths)),\n",
    "        \"min\": int(np.min(text_lengths)),\n",
    "        \"max\": int(np.max(text_lengths)),\n",
    "    },\n",
    "    \"task_distribution\": dict(task_distribution),\n",
    "    \"quality_issues\": len(issues),\n",
    "}\n",
    "\n",
    "summary_path = project_root / \"data\" / \"exploration_summary.json\"\n",
    "with open(summary_path, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"Summary saved to: {summary_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insurance-underwriting-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
